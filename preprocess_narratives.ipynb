{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ec5a2b",
   "metadata": {},
   "source": [
    "## Narrative Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334e6b69",
   "metadata": {},
   "source": [
    "Requires scispaCy model \"en_core_sci_sm\"\n",
    "\n",
    "To keep drug names together, combine number and word if word has number and hyphen, and does not contain \"year\" or \"old\"\n",
    "Remove numbers, punctuation, stopwords, and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dde27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.tokens import Token\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "nlp = spacy.load('en_core_sci_sm')\n",
    "\n",
    "# remove some stop words\n",
    "nlp.Defaults.stop_words -= {\"no\", \"not\", \"none\", \"nowhere\"}\n",
    "\n",
    "# remove period from punctuation\n",
    "my_punct = re.sub('\\.', '', string.punctuation)\n",
    "\n",
    "### set token extensions\n",
    "# has_num if has number\n",
    "num_getter = lambda token: any([t.isdigit() for t in token.text])\n",
    "Token.set_extension(\"has_num\", getter=num_getter, force=True)\n",
    "\n",
    "# has_alpha if has letter\n",
    "alpha_getter = lambda token: any([t.isalpha() for t in token.text])\n",
    "Token.set_extension(\"has_alpha\", getter=alpha_getter, force=True)\n",
    "\n",
    "# has_punct if has punctuation\n",
    "punct_getter = lambda token: any([t in string.punctuation for t in token.text])\n",
    "Token.set_extension(\"has_punct\", getter=punct_getter, force=True)\n",
    "\n",
    "# is_drug if has number and -, but not 'year' or 'old'\n",
    "drug_getter = lambda token: bool(token._.has_num and '-' in token.text\n",
    "                                 and 'year' not in token.text \n",
    "                                 and 'old' not in token.text)\n",
    "                                #and re.match(pattern='^[0-9]+\\-[a-z]+', string=token.text))\n",
    "Token.set_extension(\"is_drug\", getter=drug_getter, force = True)\n",
    "\n",
    "# returns tokens that do not have numbers or drugs\n",
    "def rm_numbers(doc):\n",
    "    return [token for token in doc if not token._.has_num or token._.is_drug]\n",
    "\n",
    "# returns tokens that do not have punctuation\n",
    "def rm_punct(doc): \n",
    "    return [token for token in doc if not token.is_punct and token.text not in string.punctuation]\n",
    "\n",
    "# returns tokens that are not stopwords\n",
    "def rm_stopwords(doc):\n",
    "    return [token for token in doc if not token.is_stop]\n",
    "\n",
    "# removes punctuation from lemma, replaces with space unless is drug\n",
    "def lemmatize(doc):\n",
    "    for token in doc:\n",
    "        if token._.is_drug:\n",
    "            token.lemma_ = ''.join(re.sub(f'[{string.punctuation}]', ' ', token.text).split())\n",
    "        elif token._.has_punct:\n",
    "            token.lemma_ = ' '.join(re.sub(r'[\\-\\/]', ' ', token.text).split())\n",
    "            token.lemma_ = ' '.join(re.sub(r'[!\"#$%&\\'()*+,.:;<=>?@[\\\\\\]^_`{|}~]', '', token.lemma_).split())\n",
    "\n",
    "    return [token.lemma_ for token in doc]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
